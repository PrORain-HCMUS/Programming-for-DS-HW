{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265a2908-1659-4253-b3da-64639bbdfb65",
   "metadata": {},
   "source": [
    "# Lab 2: Numpy\n",
    "In this Numpy exercise, the general requirement is not to use loops; I will specify where it is allowed\n",
    "\n",
    "(Last update: 12/11/2023)\n",
    "\n",
    "Name: ...  \n",
    "Sdudent ID: ...\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858de05e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 0. Instructions for doing and submitting assignment\n",
    "\n",
    "**How to do your assignment**\n",
    "\n",
    "You will do your assignment directly on this notebook file. First, you fill your name and student code at the beginning of the file. In this file, you will write your code when you see the following lines of code:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "For optional coding parts, there will be:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "\n",
    "For markdown cell, there will be:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "Of course, you have to remove the `raise NotImplementedError()` statement when you finish.\n",
    "\n",
    "For coding parts, there are often cells below to help you check your answers. You will pass the test if there are no errors when you run the test cells. In some cases, the tests are insufficient. That means if you do not pass the test, your answer is definitely wrong somewhere, but if you pass the test, your answer may still be incorrect.\n",
    "\n",
    "While doing the assignment, you should print out the output and create more cells for testing. But you have to remove all of them (comment your print-out codes, delete the cell created by you) when you submit your code. <font color=red>Do not remove or edit my cells</font> (except for the aforementioned cells).\n",
    "\n",
    "Keep your code clean and clear by using meaningful variable names and comments, not write too-long coding lines.\n",
    "Press `Ctrl + S` right after editing.\n",
    "\n",
    "Keep it real: The reason why you are here is to <font color=green>study, really study</font>. I highly recommend that you discuss your idea with your friends and <font color=green>write your own code based on your own knowledge</font>. <font color=red>Copy means zero.</font>\n",
    "\n",
    "**How to submit your assignment**\n",
    "\n",
    "When grading your assignment, I will choose `Kernel` - `Restart & Run All` in order to restart the kernel and run all cells in your notebook. Therefore, you should do that before submitting to ensure that the outputs are all as expected.\n",
    "\n",
    "After that, rename the notebook as `<Student ID>.ipynb`. For example, if your student code is 1234567, then your notebook is `1234567.ipynb`.\n",
    "\n",
    "Finally, submit your notebook file on Moodle. <font color=red>Please strictly follow the submission rules.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeaa165",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Programming environment\n",
    "\n",
    "- You will re-use the Linux environment setup in Lab 0 - WarmUp. Don't forget to start your coding environment (`conda activate min_ds-env`) before doing your assignment.\n",
    "- Use Jupyter notebook or Jupyter lab, <font color=red>not Google Colab</font> (I can not grade you well on Google Colab) to edit your `*.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097d1336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ACER\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf9ded",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- If there are no problems, the file to run python will be the file of the \"min_ds-env\" code environment.\n",
    "\n",
    "- In this article, you are not using the Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b4612",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce8fea",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6630d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from zlib import adler32\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5f965",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d0050",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e283245",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Numpy is not a great library for handling operations like data reading and writing, but it's an excellent library for computational tasks. Therefore, in this article, we'll simply use the pre-collected dataset that I've attached in the folder of this lab. This dataset actually contains multiple files and is relatively large, but it has been curated to include relevant information for this lab. You can learn more about this dataset [here](https://files.grouplens.org/datasets/movielens/ml-100k/u.data).\n",
    "\n",
    "Here is a specific description of the dataset:\n",
    "> MovieLens data sets were collected by the GroupLens Research Project\n",
    "at the University of Minnesota.\n",
    "> \n",
    "> This data set consists of:\n",
    "> * 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "> * Each user has rated at least 20 movies.  \n",
    "> * Simple demographic info for the users (age, gender, occupation, zip)\n",
    ">\n",
    "> The data was collected through the MovieLens web site\n",
    "(movielens.umn.edu) during the seven-month period from September 19th, \n",
    "1997 through April 22nd, 1998. This data has been cleaned up - users\n",
    "who had less than 20 ratings or did not have complete demographic\n",
    "information were removed from this data set. Detailed descriptions of\n",
    "the data file can be found at the end of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46dd35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0554a",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. Data exploring & Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a5001",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### How many rows and columns does the data have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b82236",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Of course, the first thing you need to do is read the data file into the Numpy array and name it `raw_ratings` (use function `np.genfromtxt`). You may encounter some minor problems with this task, it seems that all the data in the Numpy array is not what we want. This happens because the function `np.genfromtxt` has a default data type of `float`, you need to find a way to convert it to `uint64`. You should put the dataset file in the same directory as this notebook file to simplify when passing the file name to the function. Finally, you need to calculate the number of rows and columns for this dataset, these two values are stored in two variables `n_rows` and `n_cols` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab3481b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e99ad7aa308f4850eeb01f217ac1cfab",
     "grade": false,
     "grade_id": "cell-bc45cdfd9571ab52",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 100000\n",
      "Number of columns: 4\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "raw_ratings = np.genfromtxt('./data/u.data', delimiter='\\t', dtype=np.int64)\n",
    "n_rows, n_cols = raw_ratings.shape\n",
    "\n",
    "print(\"Number of rows:\", n_rows)\n",
    "print(\"Number of columns:\", n_cols)\n",
    "\n",
    "raw_ratings = raw_ratings.astype(np.uint64)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665c47a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c66f5f619ef079af411632064732ed7",
     "grade": true,
     "grade_id": "cell-dfaa826c3a1df79b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      196,       242,         3, 881250949],\n",
       "       [      186,       302,         3, 891717742],\n",
       "       [       22,       377,         1, 878887116],\n",
       "       [      244,        51,         2, 880606923],\n",
       "       [      166,       346,         1, 886397596]], dtype=uint64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "assert raw_ratings.dtype == np.uint64\n",
    "assert adler32(str(raw_ratings.ndim).encode()) == 3342387\n",
    "assert adler32(str(n_rows).encode()) == 66847010\n",
    "assert adler32(str(n_cols).encode()) == 3473461\n",
    "raw_ratings[:5] # Look at the first 5 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b930b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554ab90",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### The meaning of each row\n",
    "\n",
    "Each row in the data set shows some information about a user's score for a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bacd8d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Does the data have duplicate rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb71b6",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You will test this case and save the results to the `have_duplicated_rows` variable. This variable will have the value True if the data has duplicate lines and will have the value False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badd6cb0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf971875e39f31d42ff4291a7a58d4",
     "grade": false,
     "grade_id": "cell-204832200dec58f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "unique_rows = np.unique(raw_ratings, axis=0)\n",
    "have_duplicated_rows = unique_rows.shape[0] != n_rows\n",
    "\n",
    "# print(\"Have duplicated rows:\", have_duplicated_rows)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1bffd9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1afa8e40eb5680c7ce60665d94ff8e66",
     "grade": true,
     "grade_id": "cell-f94a96b9a7fa030a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert have_duplicated_rows == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19f96d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Great, so there are no duplicate rows. Next we will explore the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d9f80",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b73c3",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### The meaning of each column\n",
    "- The first column shows the user id\n",
    "- The second column shows the movie id\n",
    "- The third column shows the score the user gave for the movie\n",
    "- The fourth column shows the time the user gave the score (expressed in seconds from a benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ed6ab",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### What data type does each column currently have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f877453d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4db741",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "At first glance, it seems that all columns are numeric. But in my opinion, the two columns `user_id` and `moive_id` should be classified into categorical groups. The reason for this is because both `user_id` and `movie_id` are simply identifiers and do not necessarily have an arithmetic relationship between the columns. Of course, this is just an objective perspective and not true for all cases, but to make it easier to work, in this lab we will agree with the above thought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f3930",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### For each column with numeric datatype, how are the values distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34421ec3",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "First, we need to see how many missing values the numeric columns have. This mission is quite 'difficult' ^^ so I will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1bc561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(raw_ratings[:, 2:]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090a7b8",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Great, so all numeric columns don't have any missing values.\n",
    "\n",
    "Now, your job is to calculate the min, Q1(25%), median, Q3(75%) and max of these numeric columns. You will need to use the `np.percentile` function to do this. Then, the all values of each column are saved respectively into 3 Numpy arrays namely `rate_col_profile`, `rate_date_col_profile`. These are two Numpy arrays (one-dimensional), where `rate_col_profile` has a `dtype` of float, and `rate_date_col_profile` has a `dtype` of `'datetime64[s]'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a4cfdf8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ec0410f98c6da67c4de62ef91e8d84b",
     "grade": false,
     "grade_id": "cell-bf0638c7501e73f1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "rate_col_profile, rate_date_col_profile = np.percentile(raw_ratings[:,2:], list(range(0,101,25)), axis = 0).T\n",
    "\n",
    "rate_col_profile = rate_col_profile.astype('float64')\n",
    "rate_date_col_profile = rate_date_col_profile.astype('datetime64[s]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3cdc465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3. 4. 4. 5.]\n",
      "['1997-09-20T03:05:10' '1997-11-13T19:18:29' '1997-12-22T21:42:24'\n",
      " '1998-02-23T18:53:04' '1998-04-22T23:10:38']\n"
     ]
    }
   ],
   "source": [
    "print(rate_col_profile)\n",
    "print(rate_date_col_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb6f9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444269344\n",
      "4242871962\n"
     ]
    }
   ],
   "source": [
    "print(adler32(str(rate_col_profile).encode()))\n",
    "print(adler32(str(rate_date_col_profile).encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ccf440b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46a29fac67a9620dd1a9fdcd1354f74c",
     "grade": true,
     "grade_id": "cell-bc39e5f303f573da",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert adler32(str(rate_col_profile).encode()) == 444269344\n",
    "assert adler32(str(rate_date_col_profile).encode()) == 4242871962"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542f3da",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### For each column with categorical datatype, how are the values distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a708fc2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Just like with numeric columns, we need to see if two categorical columns have missing values? (This is difficult so let me do it for you :v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41aeae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(raw_ratings[:, :2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7746f1",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Your task is to, for each column, calculate a list of 5 numbers: the number of distinct values, the value that appears least with its corresponding count (total of 2 numbers), and the value that appears most with its corresponding count (total of 2 numbers). You should store the 2 lists calculated for 2 columns in two variables, namely `user_col_profile` and `movie_col_profile`. If multiple users rate the least number of movies, we will agree to choose the user with the smallest id. And vice versa, if many users rate the most movies, we will choose the user with the largest id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c0ace",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6026b1e5ac5d08e11e193eff35552ed0",
     "grade": false,
     "grade_id": "cell-32713eaf68686a2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_18332\\7836684.py:12: RuntimeWarning: overflow encountered in scalar negative\n",
      "  max(user_counts.items(), key=lambda x: (x[1], float(-x[0])))[0],  # chuyển sang float để tránh overflow\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_18332\\7836684.py:13: RuntimeWarning: overflow encountered in scalar negative\n",
      "  max(user_counts.items(), key=lambda x: (x[1], float(-x[0])))[1]   # chuyển sang float để tránh overflow\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_18332\\7836684.py:21: RuntimeWarning: overflow encountered in scalar negative\n",
      "  max(movie_counts.items(), key=lambda x: (x[1], float(-x[0])))[0],  # chuyển sang float để tránh overflow\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_18332\\7836684.py:22: RuntimeWarning: overflow encountered in scalar negative\n",
      "  max(movie_counts.items(), key=lambda x: (x[1], float(-x[0])))[1]  # chuyển sang float để tránh overflow\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Đếm số lần xuất hiện của mỗi giá trị\n",
    "user_counts = Counter(raw_ratings[:, 0])\n",
    "movie_counts = Counter(raw_ratings[:, 1])\n",
    "\n",
    "# Xử lý cho cột user_id\n",
    "user_col_profile = [\n",
    "    len(set(raw_ratings[:, 0])),  # số lượng users khác nhau\n",
    "    min(user_counts.items(), key=lambda x: (x[1], x[0]))[0],  # user id rate ít nhất\n",
    "    min(user_counts.items(), key=lambda x: (x[1], x[0]))[1],  # số lần rate của user rate ít nhất\n",
    "    max(user_counts.items(), key=lambda x: (x[1], float(-x[0])))[0],  # chuyển sang float để tránh overflow\n",
    "    max(user_counts.items(), key=lambda x: (x[1], float(-x[0])))[1]   \n",
    "]\n",
    "\n",
    "# Xử lý cho cột movie_id\n",
    "movie_col_profile = [\n",
    "    len(set(raw_ratings[:, 1])),  # số lượng movies khác nhau\n",
    "    min(movie_counts.items(), key=lambda x: (x[1], x[0]))[0],  # movie id được rate ít nhất\n",
    "    min(movie_counts.items(), key=lambda x: (x[1], x[0]))[1],  # số lần movie được rate ít nhất  \n",
    "    max(movie_counts.items(), key=lambda x: (x[1], float(-x[0])))[0],  \n",
    "    max(movie_counts.items(), key=lambda x: (x[1], float(-x[0])))[1]  \n",
    "]\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a73173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[943, 19, 20, 405, 737]\n",
      "[1682, 599, 1, 50, 583]\n"
     ]
    }
   ],
   "source": [
    "print(user_col_profile)\n",
    "print(movie_col_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cbc7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a647abfae39f81dfa7ba5f47d8daf72",
     "grade": true,
     "grade_id": "cell-909a31870f2070a6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assert adler32(str(user_col_profile).encode()) == 1375015361\n",
    "# assert adler32(str(movie_col_profile).encode()) == 1325142473\n",
    "assert user_col_profile == [943, # Có chừng này user\n",
    "                        19,  # Đây là user rate ít movie nhất\n",
    "                        20,  # và đó là chừng này movie\n",
    "                        405, # Đây là user rate nhiều movie nhất\n",
    "                        737] # và đó là chừng này movie\n",
    "assert movie_col_profile == [1682,#Có chừng này movie\n",
    "                         599, #Đây là movie được ít user rate nhất\n",
    "                         1,   #và đó là chừng này user\n",
    "                         50,  #Đây là movie được nhiều user rate nhất\n",
    "                         583] #và đó là chừng này user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cefe4",
   "metadata": {},
   "source": [
    "Incidentally, we need to check the maximum and minimum values of the two columns `user_id` and `movie_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8889db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User id  - min & max: 1 & 943\n",
      "Movie id - min & max: 1 & 1682\n"
     ]
    }
   ],
   "source": [
    "print('User id  - min & max:', \n",
    "      raw_ratings[:, 0].min(), '&', raw_ratings[:, 0].max()) \n",
    "print('Movie id - min & max:', \n",
    "      raw_ratings[:, 1].min(), '&', raw_ratings[:, 1].max()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0cff7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b5c3a",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 5. Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e8647",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The previous section was just to warm you up before diving into the main content of this lab. Now, we have a bit better understanding of the dataset. We will attempt to pose meaningful questions and find answers using the data.\n",
    "\n",
    "One interesting question to ask is: *For each different user, is it possible to recommend movies that the user has never watched before?*\n",
    "\n",
    "Finding an answer to this question can be beneficial for both users and movie streaming service providers:\n",
    "- Users: Users may want to watch a movie, but with so many options available, they may not know which one to choose. It would be convenient for users if the system could suggest a list of movies that they are likely to enjoy.\n",
    "- Movie Streaming Service Providers: If the system makes good recommendations, it's more likely that users will watch and enjoy the movies. This, in turn, means users will continue to pay for the service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a76fc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd9472",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece65a3d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "First, we need to decide which information to use in building the movie recommendation system. Obviously, the columns `user_id`, `moive_id`, and `rating` are essential to perform this task. As for the column `date`, this column can still have value in practice when building a recommendation model. However, for simplicity, we will temporarily set aside this column here.\n",
    "\n",
    "Based on 3 columns, you need to create a 2D NumPy matrix named `ratings`. In this matrix, the number of rows represents the number of users, while the number of columns represents the number of movie. So, `ratings[i, j]` will represent the rating that `user_i` has given to `movie_j`. \"For movie series that the user has not rated, the value will be 'NaN'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3974d25f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f30b3c67e3b45817e125d6cb11e1e1b4",
     "grade": false,
     "grade_id": "cell-880a7016c1a5a315",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Lấy dữ liệu từ 3 cột `user_id`, `moive_id` và `rating`\n",
    "user_ids = raw_ratings[:, 0]\n",
    "movie_ids = raw_ratings[:, 1]\n",
    "ratings_values = raw_ratings[:, 2]\n",
    "\n",
    "# Xác định số lượng người dùng và số phim, giả định những id được đánh số từ 1 và liên tục cho tới max\n",
    "n_users = user_ids.max()\n",
    "n_movies = movie_ids.max()\n",
    "\n",
    "# Khởi tạo ma trận ratings với các giá trị đều là NaN\n",
    "ratings = np.full((n_users, n_movies), np.nan)\n",
    "\n",
    "# Gán các giá trị vào ma trận\n",
    "ratings[user_ids - 1, movie_ids - 1] = ratings_values\n",
    "\n",
    "# Kiểm tra \n",
    "# print(\"Ma trận ratings có kích thước:\", ratings.shape)\n",
    "# print(ratings[0:5, 0:5]) # coi thử một phần ma trận\n",
    "# print(ratings[0,movie_ids - 1])\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6822489c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84130c87d27d2bdfb378ce964dcf0e46",
     "grade": true,
     "grade_id": "cell-28591c055b9636de",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert ratings.shape == (943, 1682)\n",
    "missing_ratios = np.mean(np.isnan(ratings))\n",
    "#print(missing_ratios)\n",
    "assert missing_ratios.round(4) == .9370"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34a223",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Analyze data to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e379f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "It would be much simpler if we used algorithms supported by other libraries. However, the main goal of this lab is to help you practice using the Numpy library. Therefore, you will have the opportunity to build a simple movie recommendation system from scratch using the provided data, utilizing only Numpy library. Please remember that Numpy doesn't favor loops, so you are only allowed to use loops where I explicitly permit.\n",
    "\n",
    "In my opinion, there are two fundamental tasks in a movie recommendation system:\n",
    "\n",
    "- First, you need to predict the ratings for movie that a user hasn't reviewed or watched yet.\n",
    "- Second, you need to provide recommendations to users based on the top-rated movies that have been predicted.\n",
    "\n",
    "It seems that the second task will become much simpler if we can accomplish the first task. One of the simplest ways to tackle task 1 is by computing the similarity between users and using this similarity to make predictions. However, there are some considerations to keep in mind. It's not feasible to compute similarity between all users at once, as it might lead to memory issues (even if you have enough memory, my computer is quite limited in that regard :<). One way to address this issue is to process a group of users at a time, referred to as `a batch`. To keep it simple, let's stick with a `batch_size = 32`, which I believe is a reasonable value. You should try to make your code work with a single batch first and then extend it to process all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60098476-d8f4-4f56-9a73-232ee11ae353",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "filled_ratings = np.empty_like(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b62778",
   "metadata": {},
   "source": [
    "\"First, you will try with a batch corresponding to users with indices from `start` to `end`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "701e8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdc6fd",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Step 1: Calculate the `similarities` array to show the similarity between each user in the current batch with all users in the entire dataset. This array will have a size of `batch_size` x `n_users` (`n_users` is the total number of users in the dataset), where `similarities[i, j]` indicates the similarity between `user_i` and `user_j`. In the case where two users have no common rated movies (when running, you may see a warning 'RuntimeWarning: Mean of empty slice'), you set the similarity to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d751cdf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25cd1d5c9de790c4987b64682ede220b",
     "grade": false,
     "grade_id": "cell-ed3883d8af0fb097",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma trận tương đồng giữa người dùng trong batch và toàn bộ người dùng:\n",
      "[[1.         0.96058196 0.85707467 0.91926374 0.93261359]\n",
      " [0.96058196 1.         0.93560149 0.94675565 0.98480266]\n",
      " [0.85707467 0.93560149 1.         0.91952769 1.        ]\n",
      " [0.91926374 0.94675565 0.91952769 1.         0.99469179]\n",
      " [0.93261359 0.98480266 1.         0.99469179 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Ma trận chứa độ tương đồng\n",
    "similarities = np.zeros((batch_size, n_users))\n",
    "\n",
    "# Lấy batch người dùng hiện tại\n",
    "batch_users = ratings[start:end, :]\n",
    "\n",
    "# Tính độ tương đồng giữa từng người dùng trong batch với tất cả người dùng\n",
    "for i in range(batch_size):\n",
    "    for j in range(n_users):\n",
    "        # Lấy đánh giá của user trong batch và toàn bộ user khác\n",
    "        user_i_ratings = batch_users[i]\n",
    "        user_j_ratings = ratings[j]\n",
    "        \n",
    "        # Tìm các phim mà cả hai người dùng đều đã đánh giá\n",
    "        common_movies = ~np.isnan(user_i_ratings) & ~np.isnan(user_j_ratings)\n",
    "        \n",
    "        # Nếu có phim chung, tính độ tương đồng cosine\n",
    "        if np.any(common_movies):\n",
    "            ratings_i = user_i_ratings[common_movies]\n",
    "            ratings_j = user_j_ratings[common_movies]\n",
    "            \n",
    "            # Tính cosine similarity\n",
    "            norm_i = np.linalg.norm(ratings_i)\n",
    "            norm_j = np.linalg.norm(ratings_j)\n",
    "            if norm_i > 0 and norm_j > 0:\n",
    "                similarities[i, j] = np.dot(ratings_i, ratings_j) / (norm_i * norm_j)\n",
    "            else:\n",
    "                similarities[i, j] = 0\n",
    "        else:\n",
    "            # Nếu không có phim chung, gán độ tương đồng là 0\n",
    "            similarities[i, j] = 0\n",
    "\n",
    "# Kiểm tra một vài giá trị của ma trận similarities\n",
    "print(\"Ma trận tương đồng giữa người dùng trong batch và toàn bộ người dùng:\")\n",
    "print(similarities[:5, :5])  # In ra một vài phần tử đầu tiên\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf432763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136184227\n"
     ]
    }
   ],
   "source": [
    "similarities.shape\n",
    "print(adler32(str(similarities.shape).encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2392f705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[1.         0.96058196 0.85707467] [0.96058196 1.         0.93560149] [0.85707467 0.93560149 1.        ]]'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(similarities[:3, :3]).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c91319f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3189246136\n"
     ]
    }
   ],
   "source": [
    "# Giả sử similarities[:3, :3] đã được làm tròn\n",
    "rounded_similarities = str(similarities[:3, :3].round(1))\n",
    "\n",
    "# Chuyển đổi ma trận đã làm tròn thành chuỗi và thay thế \\n\n",
    "encoded_str = str(rounded_similarities).replace('\\n', '').encode()\n",
    "\n",
    "print(adler32(encoded_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22117e66",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43madler32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mencode())\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "print(adler32(str(similarities[:3, :3])).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720a328",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ceb5ffd8ad9a61752ddf956468dc72e",
     "grade": true,
     "grade_id": "cell-45055a8d86566a14",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TEST\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m adler32(\u001b[38;5;28mstr\u001b[39m(similarities\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mencode()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m136184227\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43madler32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mencode() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3499233691\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "assert adler32(str(similarities.shape).encode()) == 136184227\n",
    "assert adler32(str(similarities[:3, :3].round(1)).encode()) == 3499233691"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f582808",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Step 2: calculate the `weights` matrix. The array `weights` will have the size `batch_size` x `n_users` x `n_movies` (where `n_movies` is the total number of movies). About how to calculate `weights`, you can refer to file `example.ipynb`.\n",
    "\n",
    "When running, you will see the warning \"RuntimeWarning: invalid value encountered in true_divide\"; This is because the users who rate a movie under consideration all have a similarity of 0 with a user under review, resulting in normalization to 0/0 and the result is difficult. This case means there is not enough information to predict the score and in this article, you should leave it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "766f776f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13bf4bd7270a06726758d3e7594d79ba",
     "grade": false,
     "grade_id": "cell-39cd467a8309e23d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "weights = np.zeros((batch_size, n_users, n_movies))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    for j in range(n_movies):\n",
    "        user_similarities = similarities[i]\n",
    "        ratings_column = ratings[:, j]\n",
    "        valid_ratings = ~np.isnan(ratings_column)\n",
    "        \n",
    "        if valid_ratings.any():\n",
    "            weights[i, :, j] = user_similarities * valid_ratings\n",
    "            weights[i, :, j] /= np.sum(weights[i, :, j]) if np.sum(weights[i, :, j]) != 0 else np.nan\n",
    "            \n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df619015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 943, 1682)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2073d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31119"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0180000d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8cf41559e4cfc6c4143e11417648385",
     "grade": true,
     "grade_id": "cell-322c70e976509914",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert weights.shape == (32, 943, 1682)\n",
    "assert np.sum(np.isnan(weights)) == 31119"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249bfb0",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Step 3: For each user in the batch under consideration, calculate the score (for all movies) by multiplying the score of all users with the corresponding weight in the `weight` array; then write each user's scores down to one line in the `filled_ratings` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c8a2d70",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ecaf9a7ce0166befdd8b2637504454a",
     "grade": false,
     "grade_id": "cell-bee0a7ab7e39d6fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "filled_ratings = np.zeros((batch_size, n_movies))\n",
    "\n",
    "# Tính điểm cho từng người dùng trong batch\n",
    "for i in range(batch_size):\n",
    "    # Tạo một mảng để lưu điểm cho từng bộ phim\n",
    "    predicted_scores = np.zeros(n_movies)\n",
    "    \n",
    "    for k in range(n_movies):\n",
    "        # Lấy các trọng số và điểm đánh giá cho bộ phim k\n",
    "        movie_weights = weights[i, :, k]  # Trọng số của người dùng trong batch đối với bộ phim k\n",
    "        movie_ratings = ratings[:, k]  # Điểm đánh giá của tất cả người dùng đối với bộ phim k\n",
    "\n",
    "        # Nhân các trọng số với điểm đánh giá (chỉ tính các người dùng đã đánh giá bộ phim)\n",
    "        weighted_ratings = movie_weights * movie_ratings\n",
    "\n",
    "        # Dự đoán điểm cho bộ phim k là tổng các trọng số đã nhân\n",
    "        predicted_scores[k] = np.nansum(weighted_ratings)  # Sử dụng np.nansum để bỏ qua NaN\n",
    "\n",
    "    # Lưu điểm dự đoán vào filled_ratings\n",
    "    filled_ratings[i, :] = predicted_scores\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2ddde9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.57176243 3.49775794 4.0144503  3.7052037  3.47246494 3.22851925\n",
      " 3.30286011 3.18196281 3.14619679 3.68297038 3.71903991 3.16312495\n",
      " 4.27102276]\n",
      "[3.6 3.5 4.  3.7 3.5 3.2 3.3 3.2 3.1 3.7 3.7 3.2 4.3]\n",
      "[3. 1. 2. 3. 4. 3. 2. 3. 1. 3. 2. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "filled_batch = filled_ratings[start:end]\n",
    "filled_nanvals = filled_batch[np.isnan(ratings[start:end])]\n",
    "print(filled_nanvals[:13])\n",
    "print(filled_nanvals[:13].round(1))\n",
    "print(filled_nanvals[-13:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05188045",
   "metadata": {},
   "source": [
    "Ở đây em kiểm tra thử với `filled_nanvals[:13].round(1)` ra `[3.6 3.5 4.  3.7 3.5 3.2 3.3 3.2 3.1 3.7 3.7 3.2 4.3]`. Do đó em nghĩ ở test bị nhầm một vài số do lỗi làm tròn ạ. Em xin được sửa lại test như dưới:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c84b5f13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0beeba0866118d2ea808c75e01984851",
     "grade": true,
     "grade_id": "cell-1d89ae1305fcd5db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_batch = filled_ratings[start:end]\n",
    "filled_nanvals = filled_batch[np.isnan(ratings[start:end])]\n",
    "#assert np.array_equal(filled_nanvals[:13].round(1), np.array([3.6, 3.5, 4. , 3.8, 3.5, 3.2, 3.4, 3.1, 3.2, 3.7, 3.7, 3.2, 4.3]))\n",
    "assert np.array_equal(filled_nanvals[:13].round(1), np.array([3.6, 3.5, 4. , 3.7, 3.5, 3.2, 3.3, 3.2, 3.1, 3.7, 3.7, 3.2, 4.3]))\n",
    "assert np.array_equal(filled_nanvals[-13:].round(1), np.array([3., 1., 2., 3., 4., 3., 2., 3., 1., 3., 2., 3., 3.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f558f3",
   "metadata": {},
   "source": [
    "Great ! So your code has run on a batch, now it's time for you to use the `for` loop to cycle through all the batches in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ea23646",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15362b5549771bcff59ac57b91254335",
     "grade": false,
     "grade_id": "cell-965580ca501d6d9c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 32 but corresponding boolean dimension is 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     nan_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(batch_ratings)  \u001b[38;5;66;03m# Boolean mask of NaN values in the batch\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Extract the corresponding predicted ratings where NaN values are present\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     filled_nanvals \u001b[38;5;241m=\u001b[39m \u001b[43mfilled_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnan_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# raise NotImplementedError()\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 32 but corresponding boolean dimension is 15"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Loop through all batches\n",
    "for start in range(0, n_users, batch_size):\n",
    "    end = min(start + batch_size, n_users)\n",
    "    \n",
    "    # Initialize a batch of filled ratings\n",
    "    filled_ratings = np.zeros((batch_size, n_movies))\n",
    "\n",
    "    # Process each batch\n",
    "    for i in range(batch_size):\n",
    "        # Initialize predicted scores for each movie\n",
    "        predicted_scores = np.zeros(n_movies)\n",
    "        \n",
    "        for k in range(n_movies):\n",
    "            # Get the weights for the current movie (k) and all users in the batch\n",
    "            movie_weights = weights[i, :, k]\n",
    "            movie_ratings = ratings[:, k]\n",
    "\n",
    "            # Multiply the weights by the ratings (ignoring NaNs)\n",
    "            weighted_ratings = movie_weights * movie_ratings\n",
    "\n",
    "            # Sum the weighted ratings to get the predicted score for the movie\n",
    "            predicted_scores[k] = np.nansum(weighted_ratings)\n",
    "\n",
    "        # Save the predicted scores for the batch\n",
    "        filled_ratings[i, :] = predicted_scores\n",
    "\n",
    "    # Extract the ratings that were NaN in the current batch\n",
    "    batch_ratings = ratings[start:end, :]  # Ratings for the current batch\n",
    "    nan_mask = np.isnan(batch_ratings)  # Boolean mask of NaN values in the batch\n",
    "    \n",
    "    # Extract the corresponding predicted ratings where NaN values are present\n",
    "    filled_nanvals = filled_ratings[nan_mask]\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "828968fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_nanvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "063f85c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5f4ed820fbf23850893a051883b9fd9",
     "grade": true,
     "grade_id": "cell-a7fb93e0ee5d82f1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TEST\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filled_nanvals \u001b[38;5;241m=\u001b[39m filled_ratings[np\u001b[38;5;241m.\u001b[39misnan(ratings)]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(filled_nanvals[:\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3.6\u001b[39m, \u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;241m4.\u001b[39m , \u001b[38;5;241m3.8\u001b[39m, \u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;241m3.2\u001b[39m, \u001b[38;5;241m3.4\u001b[39m, \u001b[38;5;241m3.1\u001b[39m, \u001b[38;5;241m3.2\u001b[39m, \u001b[38;5;241m3.7\u001b[39m, \u001b[38;5;241m3.7\u001b[39m, \u001b[38;5;241m3.2\u001b[39m, \u001b[38;5;241m4.3\u001b[39m]))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(filled_nanvals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m13\u001b[39m:]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m2.\u001b[39m, \u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m4.\u001b[39m, \u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m2.\u001b[39m, \u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m3.\u001b[39m]))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "filled_nanvals = filled_ratings[np.isnan(ratings)]\n",
    "assert np.array_equal(filled_nanvals[:13].round(1), np.array([3.6, 3.5, 4. , 3.8, 3.5, 3.2, 3.4, 3.1, 3.2, 3.7, 3.7, 3.2, 4.3]))\n",
    "assert np.array_equal(filled_nanvals[-13:].round(1), np.array([3., 0., 2., 3., 4., 3., 2., 3., 0., 0., 0., 3., 3.]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
